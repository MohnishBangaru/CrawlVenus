{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Async OpenAI client wrapper with retry & singleton semantics.\"\"\"\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.config import config\n",
    "from src.core.logger import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"OpenAIClient\", \"get_openai_client\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe141937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant settings\n",
    "_MAX_RETRIES = 4\n",
    "_BASE_BACKOFF = 1.0  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-capable models\n",
    "VISION_MODELS = [\n",
    "    \"gpt-4-vision-preview\",\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be82fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback model for non-vision requests\n",
    "DEFAULT_MODEL = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d645eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIClient:\n",
    "    \"\"\"Lightweight async wrapper around OpenAI chat completion API.\"\"\"\n",
    "\n",
    "    _instance: OpenAIClient | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def instance(cls) -> OpenAIClient:\n",
    "        \"\"\"Return the singleton instance, creating it on first use.\"\"\"\n",
    "        if cls._instance is None:\n",
    "            cls._instance = cls()\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the underlying async OpenAI client (internal use).\"\"\"\n",
    "        # Ensure singleton creation only once\n",
    "        if OpenAIClient._instance is not None:\n",
    "            raise RuntimeError(\"Use OpenAIClient.instance() instead of constructor\")\n",
    "\n",
    "        api_key = config.openai_api_key\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not configured\")\n",
    "        # Use new OpenAI 1.x client (sync).  Async version via openai.AsyncOpenAI\n",
    "        self._client = openai.AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "        self.model = config.openai_model\n",
    "        self.temperature = float(config.openai_temperature)\n",
    "        self.max_tokens = int(config.openai_max_tokens)\n",
    "\n",
    "    def _has_image_content(self, messages: list[dict[str, Any]]) -> bool:\n",
    "        \"\"\"Check if messages contain image content.\"\"\"\n",
    "        for message in messages:\n",
    "            content = message.get('content', [])\n",
    "            if isinstance(content, list):\n",
    "                for item in content:\n",
    "                    if isinstance(item, dict) and item.get('type') == 'image_url':\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def _get_appropriate_model(self, messages: list[dict[str, Any]]) -> str:\n",
    "        \"\"\"Get the appropriate model based on message content.\"\"\"\n",
    "        if self._has_image_content(messages):\n",
    "            # Use vision-capable model\n",
    "            if self.model in VISION_MODELS:\n",
    "                return self.model\n",
    "            else:\n",
    "                # Use a vision-capable model as fallback\n",
    "                vision_model = \"gpt-4o\"  # Most recent vision model\n",
    "                log.info(f\"Switching to vision-capable model: {vision_model}\")\n",
    "                return vision_model\n",
    "        else:\n",
    "            # Use configured model for text-only requests\n",
    "            return self.model\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Public API\n",
    "    # ---------------------------------------------------------------------\n",
    "    async def chat(\n",
    "        self,\n",
    "        *,\n",
    "        prompt: str | None = None,\n",
    "        system_prompt: str | None = None,\n",
    "        messages: list[dict[str, str]] | None = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Send chat completion request and return assistant reply.\n",
    "\n",
    "        Args:\n",
    "            prompt: Convenience user prompt string. Ignored if ``messages`` is provided.\n",
    "            system_prompt: System prompt string (used if ``messages`` is ``None``).\n",
    "            messages: Full message list to pass through; takes precedence over *prompt*.\n",
    "\n",
    "        \"\"\"\n",
    "        if messages is None:\n",
    "            if prompt is None:\n",
    "                raise ValueError(\"Either `messages` or `prompt` must be provided\")\n",
    "\n",
    "            messages = []\n",
    "            if system_prompt:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # Otherwise: caller supplied full chat history via *messages*.\n",
    "\n",
    "        backoff = _BASE_BACKOFF\n",
    "        for attempt in range(_MAX_RETRIES):\n",
    "            try:\n",
    "                response = await self._client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages,  # type: ignore[arg-type]\n",
    "                    temperature=self.temperature,\n",
    "                    max_tokens=self.max_tokens,\n",
    "                )\n",
    "                content = response.choices[0].message.content  # type: ignore[attr-defined]\n",
    "                if content is None:\n",
    "                    raise RuntimeError(\"OpenAI returned empty content\")\n",
    "                return content\n",
    "            except (openai.APIError, openai.RateLimitError) as exc:\n",
    "                if attempt == _MAX_RETRIES - 1:\n",
    "                    log.error(f\"OpenAI request failed after {attempt+1} attempts: {exc}\")\n",
    "                    raise\n",
    "                sleep_time = backoff * (2 ** attempt) + random.uniform(0, 0.5)  # noqa: S311\n",
    "                log.warning(f\"OpenAI error {exc}. Retrying in {sleep_time:.1f}s…\")\n",
    "                await asyncio.sleep(sleep_time)\n",
    "                continue\n",
    "\n",
    "        # Should not reach here\n",
    "        raise RuntimeError(\"OpenAI chat completion failed after retries\")\n",
    "\n",
    "    async def get_completion(\n",
    "        self,\n",
    "        messages: list[dict[str, Any]],\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Send chat completion request with support for text and image messages.\n",
    "\n",
    "        Args:\n",
    "            messages: List of message dictionaries that can include text and image content.\n",
    "\n",
    "        Returns:\n",
    "            Parsed response as dictionary\n",
    "        \"\"\"\n",
    "        # Determine appropriate model based on content\n",
    "        model = self._get_appropriate_model(messages)\n",
    "        \n",
    "        backoff = _BASE_BACKOFF\n",
    "        for attempt in range(_MAX_RETRIES):\n",
    "            try:\n",
    "                response = await self._client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,  # type: ignore[arg-type]\n",
    "                    temperature=self.temperature,\n",
    "                    max_tokens=self.max_tokens,\n",
    "                )\n",
    "                content = response.choices[0].message.content  # type: ignore[attr-defined]\n",
    "                if content is None:\n",
    "                    raise RuntimeError(\"OpenAI returned empty content\")\n",
    "                \n",
    "                # Try to parse as JSON\n",
    "                try:\n",
    "                    import json\n",
    "                    # Find JSON in the response\n",
    "                    start_idx = content.find('{')\n",
    "                    end_idx = content.rfind('}') + 1\n",
    "                    if start_idx != -1 and end_idx > start_idx:\n",
    "                        json_str = content[start_idx:end_idx]\n",
    "                        return json.loads(json_str)\n",
    "                    else:\n",
    "                        # If no JSON found, return as text\n",
    "                        return {\"analysis\": {\"reasoning\": content}}\n",
    "                except json.JSONDecodeError:\n",
    "                    # If JSON parsing fails, return as text\n",
    "                    return {\"analysis\": {\"reasoning\": content}}\n",
    "                    \n",
    "            except (openai.APIError, openai.RateLimitError) as exc:\n",
    "                if attempt == _MAX_RETRIES - 1:\n",
    "                    log.error(f\"OpenAI request failed after {attempt+1} attempts: {exc}\")\n",
    "                    raise\n",
    "                sleep_time = backoff * (2 ** attempt) + random.uniform(0, 0.5)  # noqa: S311\n",
    "                log.warning(f\"OpenAI error {exc}. Retrying in {sleep_time:.1f}s…\")\n",
    "                await asyncio.sleep(sleep_time)\n",
    "                continue\n",
    "\n",
    "        # Should not reach here\n",
    "        raise RuntimeError(\"OpenAI chat completion failed after retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience getter\n",
    "get_openai_client = OpenAIClient.instance "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
